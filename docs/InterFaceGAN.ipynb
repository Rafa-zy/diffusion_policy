{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InterFaceGAN",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJDJLE3v0HNr"
      },
      "source": [
        "# Fetch Codebase and Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqiWKjpFa0ov"
      },
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'interfacegan'\n",
        "!git clone https://github.com/genforce/interfacegan.git $CODE_DIR\n",
        "os.chdir(f'./{CODE_DIR}')\n",
        "!wget https://www.dropbox.com/s/t74z87pk3cf8ny7/pggan_celebahq.pth?dl=1 -O models/pretrain/pggan_celebahq.pth --quiet\n",
        "!wget https://www.dropbox.com/s/nmo2g3u0qt7x70m/stylegan_celebahq.pth?dl=1 -O models/pretrain/stylegan_celebahq.pth --quiet\n",
        "!wget https://www.dropbox.com/s/qyv37eaobnow7fu/stylegan_ffhq.pth?dl=1 -O models/pretrain/stylegan_ffhq.pth --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Example: assuming `logits` and `target` are given as in your prompt\n",
        "# logits: a tensor of shape (N,) containing raw model outputs\n",
        "# target: a tensor of shape (N,) containing binary targets (0 or 1)\n",
        "\n",
        "# Move to CPU if needed for convenience\n",
        "\n",
        "logits = torch.Tensor([-3.0813, -2.7326, -2.6744, -3.1925, -3.1252, -3.0202, -2.6410, -2.6767,\n",
        "        -2.7518, -2.3882, -2.1411, -2.1445, -2.3628, -2.2263, -1.6456, -1.4816,\n",
        "        -1.5147, -1.8712, -2.3281, -1.2492, -1.6325, -1.7663, -2.3497, -1.5732,\n",
        "        -2.9816, -0.7313,  4.8540,  3.9881,  2.8537,  0.8065, -0.2259, -1.8881,\n",
        "        -3.4959, -3.4890, -3.3142, -2.3146,  0.9305,  4.0203,  4.2909,  0.5521,\n",
        "        -1.7669, -2.2790, -2.8760, -3.5149, -4.3619, -3.6258, -2.6459, -0.9345,\n",
        "        -1.5497, -2.0403, -2.7297, -3.2027, -2.9482, -2.9794, -2.6976, -2.5041,\n",
        "        -2.6205, -2.7988, -3.2494, -3.9625, -4.8243, -4.6476, -4.5740, -4.2531,\n",
        "        -4.4044, -3.7544, -2.7661, -2.2310, -1.6748, -1.8338, -1.4787, -1.2494,\n",
        "        -2.7115, -5.0668, -4.1165, -3.8642, -4.0189, -4.7250, -4.4684, -4.0874,\n",
        "        -3.4787, -2.8414, -2.1056, -2.1562, -1.6510, -2.3813, -2.9373, -3.9663,\n",
        "        -3.8931, -4.7146, -5.2370, -5.4161, -5.4001, -5.6786, -5.8130, -5.2401,\n",
        "        -5.0327, -4.0818, -3.9750, -3.6059, -2.7205, -3.4247, -2.6133, -3.3164,\n",
        "        -2.7745, -3.5136, -4.8083, -4.7210, -4.8444, -6.0597, -7.3764, -6.1789,\n",
        "        -5.9047, -4.2788, -2.6912, -3.0796, -4.6649, -4.8408, -2.8171, -1.9880,\n",
        "        -2.7772, -3.3729, -4.0426, -4.3224, -5.5752, -3.6222, -1.0536, -0.8885,\n",
        "        -0.9608, -2.6265, -2.8245, -3.2279, -2.7178, -1.7976, -2.0546, -0.4930,\n",
        "        -0.5180, -0.4030, -0.4326, -0.5329, -0.3162, -0.5455, -0.5112, -0.6612,\n",
        "        -0.4980, -0.3771,  0.0781, -0.5769, -0.2705, -1.7153, -1.3081, -1.0893,\n",
        "        -1.0500, -1.4353, -1.0977, -0.9222, -1.0024, -1.8311, -4.3220, -3.4176,\n",
        "        -3.4725, -0.7882, -1.0219, -3.3603, -3.1582, -4.8302,  0.2268,  1.7615,\n",
        "         1.8765,  1.9743,  1.9806,  2.0206,  1.8210,  1.9132,  1.7035,  1.6427,\n",
        "         1.6034,  1.4837,  1.7513,  1.9145,  1.7348,  1.3234,  0.7830, -1.4339,\n",
        "        -0.8965, -0.2651, -0.1459,  0.0830,  0.5303,  0.7212,  0.4605, -0.1563,\n",
        "        -1.1421, -1.1999, -1.3423, -1.4161, -1.5219, -3.1960, -3.4693, -3.5721,\n",
        "        -4.3226, -4.6781, -3.3699, -3.1659, -2.0975, -3.1098, -2.5532, -2.6166,\n",
        "        -1.2580, -1.0874, -1.4851, -0.2570,  0.5835, -1.9743, -1.2703, -0.7100,\n",
        "         0.6660, -1.6069,  2.6124,  1.7735,  0.8902, -0.7988,  0.6925,  1.8535,\n",
        "        -3.4347, -2.9645, -2.6593, -1.7674,  0.0293,  4.0762,  6.9749,  7.9871,\n",
        "         7.3510,  7.0330,  4.2164,  2.7169, -3.5920, -1.8445, -1.4673,  0.2575,\n",
        "         1.8804,  2.0015,  1.9398,  1.7426,  1.8010,  1.7097,  1.6382,  2.1093,\n",
        "         2.4961,  2.3372,  1.8368,  1.4096,  1.7101,  1.9323,  1.8410, -0.5481,\n",
        "        -0.1839, -2.2910, -3.2015, -1.1768, -4.6493, -4.9197, -5.3586, -5.2399,\n",
        "        -2.2852, -3.3820, -2.5723, -0.9342,  0.5087, -0.1254])\n",
        "target = torch.Tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
        "        1, 1, 1, 1, 1, 1])\n",
        "\n",
        "logits_cpu = logits.detach().cpu()\n",
        "target_cpu = target.detach().cpu()\n",
        "\n",
        "# Generate a range of thresholds\n",
        "num_thresholds = 100\n",
        "thresholds = torch.linspace(logits_cpu.min(), logits_cpu.max(), steps=num_thresholds)\n",
        "\n",
        "best_threshold = None\n",
        "best_f1 = -1.0\n",
        "\n",
        "for th in thresholds:\n",
        "    preds = (logits_cpu > th).int()\n",
        "    current_f1 = f1_score(target_cpu.numpy(), preds.numpy(), zero_division=0)\n",
        "    if current_f1 > best_f1:\n",
        "        best_f1 = current_f1\n",
        "        best_threshold = th.item()\n",
        "\n",
        "print(f\"Best threshold: {best_threshold}\")\n",
        "print(f\"Best F1-score: {best_f1}\")\n",
        "Interpretation:\n",
        "\n",
        "The code tries different thresholds uniformly spaced between the minimum and maximum logit values.\n",
        "For each threshold, it computes the F1-s"
      ],
      "metadata": {
        "id": "R4K6oNY8FnNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ_IXBZr8YcJ"
      },
      "source": [
        "# Define Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijKTlG5GeTd3"
      },
      "source": [
        "import os.path\n",
        "import io\n",
        "import IPython.display\n",
        "import numpy as np\n",
        "import cv2\n",
        "import PIL.Image\n",
        "\n",
        "import torch\n",
        "\n",
        "from models.model_settings import MODEL_POOL\n",
        "from models.pggan_generator import PGGANGenerator\n",
        "from models.stylegan_generator import StyleGANGenerator\n",
        "from utils.manipulator import linear_interpolate\n",
        "\n",
        "\n",
        "def build_generator(model_name):\n",
        "  \"\"\"Builds the generator by model name.\"\"\"\n",
        "  gan_type = MODEL_POOL[model_name]['gan_type']\n",
        "  if gan_type == 'pggan':\n",
        "    generator = PGGANGenerator(model_name)\n",
        "  elif gan_type == 'stylegan':\n",
        "    generator = StyleGANGenerator(model_name)\n",
        "  return generator\n",
        "\n",
        "\n",
        "def sample_codes(generator, num, latent_space_type='Z', seed=0):\n",
        "  \"\"\"Samples latent codes randomly.\"\"\"\n",
        "  np.random.seed(seed)\n",
        "  codes = generator.easy_sample(num)\n",
        "  if generator.gan_type == 'stylegan' and latent_space_type == 'W':\n",
        "    codes = torch.from_numpy(codes).type(torch.FloatTensor).to(generator.run_device)\n",
        "    codes = generator.get_value(generator.model.mapping(codes))\n",
        "  return codes\n",
        "\n",
        "\n",
        "def imshow(images, col, viz_size=256):\n",
        "  \"\"\"Shows images in one figure.\"\"\"\n",
        "  num, height, width, channels = images.shape\n",
        "  assert num % col == 0\n",
        "  row = num // col\n",
        "\n",
        "  fused_image = np.zeros((viz_size * row, viz_size * col, channels), dtype=np.uint8)\n",
        "\n",
        "  for idx, image in enumerate(images):\n",
        "    i, j = divmod(idx, col)\n",
        "    y = i * viz_size\n",
        "    x = j * viz_size\n",
        "    if height != viz_size or width != viz_size:\n",
        "      image = cv2.resize(image, (viz_size, viz_size))\n",
        "    fused_image[y:y + viz_size, x:x + viz_size] = image\n",
        "\n",
        "  fused_image = np.asarray(fused_image, dtype=np.uint8)\n",
        "  data = io.BytesIO()\n",
        "  PIL.Image.fromarray(fused_image).save(data, 'jpeg')\n",
        "  im_data = data.getvalue()\n",
        "  disp = IPython.display.display(IPython.display.Image(im_data))\n",
        "  return disp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7gkmrVW8eR1"
      },
      "source": [
        "# Select a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoWI4fPQ6Gnf"
      },
      "source": [
        "#@title { display-mode: \"form\", run: \"auto\" }\n",
        "model_name = \"stylegan_ffhq\" #@param ['pggan_celebahq','stylegan_celebahq', 'stylegan_ffhq']\n",
        "latent_space_type = \"W\" #@param ['Z', 'W']\n",
        "\n",
        "generator = build_generator(model_name)\n",
        "\n",
        "ATTRS = ['age', 'eyeglasses', 'gender', 'pose', 'smile']\n",
        "boundaries = {}\n",
        "for i, attr_name in enumerate(ATTRS):\n",
        "  boundary_name = f'{model_name}_{attr_name}'\n",
        "  if generator.gan_type == 'stylegan' and latent_space_type == 'W':\n",
        "    boundaries[attr_name] = np.load(f'boundaries/{boundary_name}_w_boundary.npy')\n",
        "  else:\n",
        "    boundaries[attr_name] = np.load(f'boundaries/{boundary_name}_boundary.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDStH1O5t1KC"
      },
      "source": [
        "# Sample latent codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlRGKZbJt9hA"
      },
      "source": [
        "#@title { display-mode: \"form\", run: \"auto\" }\n",
        "\n",
        "num_samples = 4 #@param {type:\"slider\", min:1, max:8, step:1}\n",
        "noise_seed = 0 #@param {type:\"slider\", min:0, max:1000, step:1}\n",
        "\n",
        "latent_codes = sample_codes(generator, num_samples, latent_space_type, noise_seed)\n",
        "if generator.gan_type == 'stylegan' and latent_space_type == 'W':\n",
        "  synthesis_kwargs = {'latent_space_type': 'W'}\n",
        "else:\n",
        "  synthesis_kwargs = {}\n",
        "\n",
        "images = generator.easy_synthesize(latent_codes, **synthesis_kwargs)['image']\n",
        "imshow(images, col=num_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmRPN3xz8jCH"
      },
      "source": [
        "# Edit facial attributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccONBF60mVir"
      },
      "source": [
        "#@title { display-mode: \"form\", run: \"auto\" }\n",
        "\n",
        "age = 0 #@param {type:\"slider\", min:-3.0, max:3.0, step:0.1}\n",
        "eyeglasses = 0 #@param {type:\"slider\", min:-2.9, max:3.0, step:0.1}\n",
        "gender = 0 #@param {type:\"slider\", min:-3.0, max:3.0, step:0.1}\n",
        "pose = 0 #@param {type:\"slider\", min:-3.0, max:3.0, step:0.1}\n",
        "smile = 0 #@param {type:\"slider\", min:-3.0, max:3.0, step:0.1}\n",
        "\n",
        "new_codes = latent_codes.copy()\n",
        "for i, attr_name in enumerate(ATTRS):\n",
        "  new_codes += boundaries[attr_name] * eval(attr_name)\n",
        "\n",
        "new_images = generator.easy_synthesize(new_codes, **synthesis_kwargs)['image']\n",
        "imshow(new_images, col=num_samples)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}